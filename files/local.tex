\subsection{Localization}\label{sec:local}

In this subsection we formulate a local version of the main theorem.
This version is more general, but its proof require just slight change of language.
A couple of times we had to use this local version in the proof;
so in a perfect world we had to rewire the whole paper using this language.
However, this is not a principle moment,
so we decided to keep paper more readable at the cost of being not fully rigorous.
A more systematic discussion of the this topic is given in \cite{LNep}.

First we need to define Alexandrov region;
its main example is an open set in Alexandrov space.

\begin{thm}{Definition}
Let $A$ be a locally compact metric space. 
We say that a point  $p\in A$
is  \emph{ $\eps$-inner point} if
the closed ball $\bar B(x,2\cdot\eps)$ is compact.
\end{thm}

\begin{thm}{Definition}
We say that a locally compact inner metric space $A$ of finite Hausdorff dimension
is an \emph{Alexandrov region} if
any point has a neighborhood where Alexandrov
comparison for curvature $\ge -1$ holds.

The \emph{comprison radius} $r_c(p)$ for $p\in A$ is defined as 
the maximal number $r$ such that
$p$ is $r$-inner point and Alexandrov
comparison for curvature $\ge -1$ holds in
$B(x,r)$.
\end{thm}

Any point $p$ in an Alexandrov region admits a convex neighborhood.
Moreover, its size can be controlled in terms of dimension, $r_c(p)$ and lower bound on volume of the ball $B(p,r_c)$.
The construction is the same as for Alexandrov space \cite[4.3]{perelman-petrunin}.

By the globalization theorem (see, for example, \cite{AKP}), a compact convex subset in an Alexandrov region is an Alexandrov space.
So the statement above makes it possible to apply most of the arguments and constructions for Alexandrov spaces to Alexandrov regions. 
Moreover, in the case when Alexandrov region is a Riemannian manifold (possibly noncomplete) it is possible to take the doubling of convex neighborhood from the Proposition
and smooth it with almost the same lower curvature bound.
This allows us to apply the main result from \cite{petrunin-SC}, where the complete manifold can be replaced by a convex domain in a possibly open manifold. 

Further, let us define a local version of smoothing.
Let us denote by
$\M_{\ge -1}^m$ a class of $m$-dimensional Riemannian 
manifolds without boundary, but possibly non-complete, with sectional curvature bounded
from below by $-1$.

\begin{thm}{Definition}
Let 
$M_n\in\M_{\ge -1}^m$ (with corresponding intrinsic metric)
converges in Gromov--Hausdorff sense to some metric space $A$ via
approximation.
Suppose that $M_n\ni x_n\to x\in A$
and $r_c(x_n)\ge c_0>0$. Let $c_{conv}(m)c_0 > R>0$ and set
$U_n=B(x_n,R)_{M_n}$.
Then we say that $U_n$ is a local smoothing of $U=B(x,R)_A$ (briefly, $U_n\smooths{} U$).
\end{thm}

It is straightforward to redefine test functions and weak convergence for local smoothings.
Using this language we can make local version for each statement in this paper, the proofs go without changes.
As a result, we get the following local version of the main theorem \ref{main}.
 
\begin{thm}{Local version of the main theorem}\label{mainloc}
Let   
$M_n\in\M_{\ge -1}^m$,
$M_n\GHto A$, $U_n\subset M_m$,
  $U\subset A$, and $U_n\smooths{} U$ be a local smoothing.
  
Denote by $\qm_n$ the dual measure-valued curvature tensor on $U_n$.
Then there is a measure-valued tensor $\qm$ on $U$ such that $\qm_n\rightharpoonup \qm$.
\end{thm}





\subsection{A more conceptual definition of convergence}

Here we will describe a more natural definition of convergence that is equivalent to our definition.
It is given for purely aesthetic purposes --- we did not use it and do not see its application.
By that reason, we give only definitions and do not prove equivalence.

\parbf{Convergence of vectors.}
Let $A$ be an Alexandrov space, we denote by $\T A$ the set of all tangent vectors at all points.
So far $\T A$ is a disjoint union of all tangent cones;
let us define convergence on it.

Recall that gradient exponent $\gexp\: \T A\to A$ is defined in \cite{AKP}.
Given a vector $V\in \T A$, it defines its gradient curve $\gamma_{V}\:t\mapsto \gexp (t\cdot V)$.
We say that a sequence of vectors $V_n\in \T A$ converges to $V\in \T A$ if $\gamma_{V_n}$ converges to $\gamma_V$ pointwise.
Since the gradient curve $\gamma_V$ is $|V|$-Lipschitz, we get that for any bounded sequence of vectors with base points in a bounded set have a converging subsequence of $\gamma_{V_n}$.
Further, the pointwise limit of such curves is a gradient curve as well.
Therefore, any bounded sequence of tangent vectors with base points in a bounded set has a converging sequence.

A direct analog holds for sequences of Alexandrov spaces $A_n$ that converge to $A$.
That is, if $V_n\in \T A_n$ is a bounded sequence of tangent vectors with bounded set of base points, then it has a subsequence that converges to some vector $V\in \T A$.

Note that 
\[|V|\le \lim |V_n|\]
and the inequality might be strict.




\parbf{$\bm{C^1}$-delta smooth functions and their convergence.}
Given a function $f\:A\to \RR$ and a vector $V\in \T A$, set
\[Vf=(f\circ\gamma_V(t))'|_{t=0}.\]
Note that $Vf$ is defined for all DC-functions.

Two vectors $V,W\in \T_pA$ will be called $\delta$-opposite if
$1-\delta< |V|\le 1$,
$1-\delta< |W|\le 1$,
and $|\langle X,V\rangle +\langle X,W\rangle|<\delta$ for any unit vector $X\in T_p A$.
We say that $V,W\in \T_pA$ are opposite if they are $\delta$-opposite for any $\delta>0$;
in this case, they are both unit vectors and make angle $\pi$ to each other.  

A Lipschitz function $f\:A\to \RR$ will be called \emph{$C^1$-delta smooth} if $Vf$ is defined for any unit vector $V$ and it satisfies the following continuity property:
for any $\eps>0$ there is $\delta>0$ such that if unit vectors $V_n$ converge to $V$ and $V$ has a $\delta$-opposite vector, then 
\[|Vf-\lim V_nf|<\eps.\eqlbl{eq:Vf}\]

Similarly, we can define $C^1$-delta converging sequence of functions.
Namely, suppose $A_n\GHto A$, then a sequence of $C^1$-delta smooth functions $f_n\:A_n\to\RR$ \emph{$C^1$-delta converges} to $f\:A\to \RR$ if for any $\eps>0$ there is $\delta>0$ such that any sequence of unit vectors $V_n\in \T A_n$ that converges to a vector $V\in \T A$ that has a $\delta$-opposite vector \ref{eq:Vf} holds. 

\parbf{Weak convergence of tensor fields.}
It is easy to see that test-convergence implies $C^1$-delta convergence.
The latter notion seems to be more natural.
If we replace test convergence
by $C^1$-delta convergence
in the definition of the weak convergence of tensor fields and
formulate the main theorem using this definition, we get formally stronger
statement but in fact our proof 
still works for this.

For the part with DC-calculus and 
Key lemma we still use test sequences
(note that $C^1$-delta smooth functions are not DC in general).
Then we need the following property:
\begin{itemize}
 \item \textit{For any test sequence $f_n$ and any $C^1$-delta converging sequence $g_n$ the function
$\langle \nabla f_n , \nabla g_n
\rangle$ delta-converges.}
\end{itemize}
Its proof reminds the proof of differentiability of a function that has continuous partial derivatives. 
